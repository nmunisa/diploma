{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QObZxD3Pf67W"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Практика"
      ],
      "metadata": {
        "id": "oexUtbleYz1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Скачивание данных"
      ],
      "metadata": {
        "id": "UNpKRJ6bZM1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Работа с google drive"
      ],
      "metadata": {
        "id": "gGybbSTqE-QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk7LSj86E8l1",
        "outputId": "f5abf841-4f7a-4ef1-b5d5-e18962a6b744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#копирование cancer_detection.zip в content\n",
        "!cp /content/drive/MyDrive/Colab_Notebooks/diploma/dataset/cancer_detection.zip /content/"
      ],
      "metadata": {
        "id": "WpDLGrOeFNIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#проверка, что cancer_detection.zip находится в content\n",
        "!ls /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0TMc-UbRVoA",
        "outputId": "a4bc00d2-96a1-4bd5-fe01-4cd6429a70c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cancer_detection.zip  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/cancer_detection.zip\""
      ],
      "metadata": {
        "id": "EHvEmnnIRYa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "Cboy8Tj6ZvUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_transforms = transforms.Compose([\n",
        "        transforms.Resize(256), # размер каждой картинки будет приведен к 256*256\n",
        "        transforms.CenterCrop(224), # у картинки будет вырезан центральный кусок размера 224*224\n",
        "        # transforms.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
        "        transforms.ToTensor(), # картинка из питоновского массива переводится в формат torch.Tensor\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # значения пикселей картинки нормализуются\n",
        "    ])"
      ],
      "metadata": {
        "id": "yB-xgRtUZk9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uv0bmw5aSzuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder('./cancer_detection/train', transform=resnet_transforms)\n",
        "#val_data = datasets.ImageFolder('./cancer_detection/valid', transform=resnet_transforms)\n",
        "test_data = datasets.ImageFolder('./cancer_detection/test', transform=resnet_transforms)\n",
        "\n",
        "# делим тренировочную часть на train и val\n",
        "\n",
        "# в тренировочную выборку отнесем 80% всех картинок\n",
        "train_size = int(len(train_data) * 0.8)\n",
        "# в валидационную — остальные 20%\n",
        "val_size = len(train_data) - train_size\n",
        "\n",
        "train_data, val_data = torch.utils.data.random_split(train_data, [train_size, val_size])"
      ],
      "metadata": {
        "id": "KXqCM0OVZv3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "i8kx_6FaZ6AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Замена последнего слоя сети"
      ],
      "metadata": {
        "id": "qsyARWZHZ-Hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузим модель, которую будем дообучать:"
      ],
      "metadata": {
        "id": "-YZIDvydaD0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "model"
      ],
      "metadata": {
        "id": "8t53zdBqZ8DU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7463605c-ae23-4891-a316-dbf2486eb234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 345MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc"
      ],
      "metadata": {
        "id": "DEXS1YopaIHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d2a4c9-0aa6-4ebb-cc09-bac060709ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=512, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заменим последний слой сети на новый, содержащий 70 нейронов (так как у нас 70 классов в датасете):"
      ],
      "metadata": {
        "id": "N9-P3yN2aKMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Linear(512, 1)\n",
        "# скорее всего сюда добавим лосс ф-уию либо туда где она вызывается\n",
        "model"
      ],
      "metadata": {
        "id": "LEk5G43XaIw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce37d14b-60aa-4b21-d252-34c669c2696f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Заморозка слоев"
      ],
      "metadata": {
        "id": "djio18LzaN7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.children() выдает список сабмодулей нейросети\n",
        "# в нашем случае это блоки resnet \n",
        "len(list(model.children()))"
      ],
      "metadata": {
        "id": "cRrc4KSQaNf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9dac01-a7e4-472f-9b06-fd940684d941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заморозим все сверточные слои:"
      ],
      "metadata": {
        "id": "uTd4djlVaVV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# проходимся по блокам нейросети\n",
        "for i, layer in enumerate(model.children()):\n",
        "\n",
        "  # заморозим первые девять блоков \n",
        "  if i < 9:\n",
        "    # проходимся по всем весам (параметрам) блока\n",
        "    for param in layer.parameters():\n",
        "      # замораживаем паарметр\n",
        "      param.requires_grad = False"
      ],
      "metadata": {
        "id": "zdV4GtNwaTnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Соберем весь код подготовки вместе:"
      ],
      "metadata": {
        "id": "emk6IDcxa5CE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model, num_out_classes, num_freeze_layers=None):\n",
        "    # замена последнего слоя сети\n",
        "    model.fc = nn.Linear(512, num_out_classes)\n",
        "\n",
        "    # заморозка слоев\n",
        "    if num_freeze_layers is not None:\n",
        "        for i, layer in enumerate(model.children()):\n",
        "            if i < num_freeze_layers:\n",
        "                for param in layer.parameters():\n",
        "                    param.requires_grad = False\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "1lUWsSSXwkkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(models.resnet18(pretrained=True), 1)"
      ],
      "metadata": {
        "id": "FmKtksHJbO2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Обучение сети"
      ],
      "metadata": {
        "id": "vzLTn1UwaYTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перенесем нашу нейросеть на GPU, если GPU доступен:"
      ],
      "metadata": {
        "id": "J2F4XK4-aan0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "kU3tCKikaZkS",
        "outputId": "e1545c10-2d8c-46a8-84f4-3ab7d777465a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем функции для обучения сети"
      ],
      "metadata": {
        "id": "LhGEn39uYBIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def evaluate(model, dataloader, loss_fn):\n",
        "    losses = []\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    num_correct = 0\n",
        "    num_elements = 0\n",
        "\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        # получаем текущий батч\n",
        "        X_batch, y_batch = batch\n",
        "        num_elements += len(y_batch)\n",
        "\n",
        "        # добавляем дополнительное измерение к целевым меткам\n",
        "        y_batch = y_batch.unsqueeze(1).float().to(device)\n",
        "\n",
        "        # эта строка запрещает вычисление градиентов\n",
        "        with torch.no_grad():\n",
        "            # получаем ответы сети на картинки батча\n",
        "            logits = model(X_batch.to(device))\n",
        "\n",
        "            # вычисляем лосс на текущем батче\n",
        "            loss = loss_fn(logits, y_batch)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # вычисляем ответы сети\n",
        "            y_pred = torch.round(torch.sigmoid(logits)) # применяем сигмоиду и округляем\n",
        "\n",
        "            # вычисляем количество правильных ответов сети в текущем батче\n",
        "            num_correct += torch.sum(y_pred.cpu() == y_batch.cpu())\n",
        "\n",
        "            # сохраняем прогнозы и целевые метки для вычисления ROC AUC\n",
        "            predictions.append(y_pred.cpu().numpy())\n",
        "            targets.append(y_batch.cpu().numpy())\n",
        "\n",
        "    # вычисляем итоговую долю правильных ответов\n",
        "    accuracy = (num_correct / num_elements).cpu().numpy()\n",
        "\n",
        "    # вычисляем ROC AUC\n",
        "    predictions = np.concatenate(predictions)\n",
        "    targets = np.concatenate(targets)\n",
        "    roc_auc = roc_auc_score(targets, predictions)\n",
        "\n",
        "    return accuracy, np.mean(losses), roc_auc\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def train(model, loss_fn, optimizer, n_epoch=3):\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    train_roc_aucs = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    val_roc_aucs = []\n",
        "    train_iterations = []\n",
        "    \n",
        "    # цикл обучения сети\n",
        "    for epoch in range(n_epoch):\n",
        "        print(\"Epoch:\", epoch+1)\n",
        "        model.train(True)\n",
        "        \n",
        "        for i, batch in enumerate(train_loader):\n",
        "            # получаем текущий батч\n",
        "            X_batch, y_batch = batch \n",
        "            y_batch = y_batch.unsqueeze(1).float().to(device)\n",
        "            \n",
        "            # forward pass (получение ответов на батч картинок)\n",
        "            logits = model(X_batch.to(device)) \n",
        "            \n",
        "            # вычисление лосса от выданных сетью ответов и правильных ответов на батч\n",
        "            loss = loss_fn(logits, y_batch) \n",
        "            train_losses.append(loss.item())\n",
        "            \n",
        "            loss.backward() # backpropagation (вычисление градиентов)\n",
        "            optimizer.step() # обновление весов сети\n",
        "            optimizer.zero_grad() # обнуляем веса\n",
        "            \n",
        "            # вычислим accuracy на текущем train батче\n",
        "            model_answers = torch.round(torch.sigmoid(logits))  # применяем сигмоиду и округляем\n",
        "            train_accuracy = torch.sum(y_batch.cpu() == model_answers.cpu()) / len(y_batch)\n",
        "            train_accuracies.append(train_accuracy.item())\n",
        "            \n",
        "            # вычислим ROC AUC на текущем train батче\n",
        "            train_roc_auc = roc_auc_score(y_batch.detach().cpu().numpy(), model_answers.detach().cpu().numpy())\n",
        "            train_roc_aucs.append(train_roc_auc)\n",
        "            \n",
        "            train_iterations.append((epoch * len(train_loader)) + i + 1)\n",
        "\n",
        "            # выведем лосс, accuracy и ROC AUC на график раз в print_freq итераций обучения\n",
        "            if (i+1) % 2000 == 0:\n",
        "                fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "                \n",
        "                axes[0].plot(train_iterations, train_losses)\n",
        "                axes[0].set_title('Train losses')\n",
        "                axes[0].set(xlabel='Iterations', ylabel='Loss')\n",
        "                \n",
        "                axes[1].plot(train_iterations, train_accuracies)\n",
        "                axes[1].set_title('Train accuracies')\n",
        "                axes[1].set(xlabel='Iterations', ylabel='Accuracy')\n",
        "                \n",
        "                axes[2].plot(train_iterations, train_roc_aucs)\n",
        "                axes[2].set_title('Train ROC AUC')\n",
        "                axes[2].set(xlabel='Iterations', ylabel='ROC AUC')\n",
        "                \n",
        "                plt.show()\n",
        "\n",
        "                clear_output(wait=True)\n",
        "\n",
        "        # после каждой эпохи получаем метрику качества на валидационной выборке\n",
        "        model.train(False)\n",
        "        val_accuracy, val_loss, val_roc_auc = evaluate(model, val_loader, loss_fn=loss_fn)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "        val_roc_aucs.append(val_roc_auc)\n",
        "        print(\"Эпоха {}/{}: val лосс, accuracy и ROC AUC:\".format(epoch+1, n_epoch), val_loss, val_accuracy, val_roc_auc, end='\\n')\n",
        "        \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "2LAQ4v_cuGNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# снова объявим модель\n",
        "model = create_model(models.resnet18(pretrained=True), 1)\n",
        "model = model.to(device)\n",
        "\n",
        "# выбираем функцию потерь\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# выбираем алгоритм оптимизации и learning_rate. \n",
        "# вы можете экспериментировать с разными значениями learning_rate\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "fLG6e8BDampA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запуск обучения модели"
      ],
      "metadata": {
        "id": "5GDWvnfPYIKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# запустим обучение модели\n",
        "# параметр n_epoch можно варьировать\n",
        "\n",
        "start = timeit.default_timer()\n",
        "\n",
        "model = train(model, loss_fn, optimizer, n_epoch=15)\n",
        "\n",
        "end = timeit.default_timer()\n",
        "execution_time = end - start\n",
        "\n",
        "# Преобразуем время в часы, минуты и секунды\n",
        "hours, rem = divmod(execution_time, 3600)\n",
        "minutes, seconds = divmod(rem, 60)\n",
        "\n",
        "print(f\"Обучение длилось: {int(hours)} часов, {int(minutes)} минут, {seconds:.2f} секунд\")"
      ],
      "metadata": {
        "id": "y-W7vOK2bdZi",
        "outputId": "08be577f-a354-4a4c-f8f9-b93a9a81dac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 12/15: val лосс, accuracy и ROC AUC: 0.20167119707641473 0.95177823 0.9462669103464645\n",
            "Epoch: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Прогоняем датасет test через сеть и получаем ответы"
      ],
      "metadata": {
        "id": "MLZs1OwMboj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(model, dataloader):\n",
        "    \n",
        "    answers_arr = []\n",
        "  \n",
        "    images_pathes = [x[0] for x in dataloader.sampler.data_source.imgs]\n",
        "\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        \n",
        "        # получаем текущий батч\n",
        "        X_batch, y_batch = batch\n",
        "        \n",
        "      \n",
        "        \n",
        "        # эта строка запрещает вычисление градиентов\n",
        "        with torch.no_grad():\n",
        "            # получаем ответы сети на картинки батча\n",
        "            logits = model(X_batch.to(device))\n",
        "            \n",
        "            \n",
        "            # вычисляем ответы сети\n",
        "            y_pred = torch.sigmoid(logits) # применяем сигмоиду и округляем\n",
        "            \n",
        "            answers_arr.extend(y_pred.data.cpu().numpy())\n",
        "\n",
        "            \n",
        "            \n",
        "    return answers_arr, images_pathes"
      ],
      "metadata": {
        "id": "n3dQNMNWMuOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers_arr, images_pathes = get_answer(model, test_loader)"
      ],
      "metadata": {
        "id": "G8QYejiZVFyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Создание csv файла для отправки в kaggle"
      ],
      "metadata": {
        "id": "3NSMaVqCW5--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверка, преобразование к нежному виду и проверка массива с идентификаторами\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Cnsmja3sgXXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_pathes"
      ],
      "metadata": {
        "id": "2m_vSO1hR6CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_names = [path.split('/')[-1].replace('.tif', '') for path in images_pathes]"
      ],
      "metadata": {
        "id": "afLDwVNuRq0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_names"
      ],
      "metadata": {
        "id": "HzJpGPLIc9Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверка, преобразование и проверка массива с ответами"
      ],
      "metadata": {
        "id": "TPVUUuVpgkj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answers_arr"
      ],
      "metadata": {
        "id": "jHXKausHgDea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = [float(arr[0]) for arr in answers_arr]\n",
        "\n",
        "answers"
      ],
      "metadata": {
        "id": "pDc5w04ofZ9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Проверка, что количество элементов в обоих массивах одинаково\n",
        "if len(answers) != len(images_names):\n",
        "    print(\"Количество элементов в массивах не совпадает.\")\n",
        "    exit()\n",
        "\n",
        "# Создание CSV файла и запись данных\n",
        "with open(\"output.csv\", \"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"id\", \"label\"])  # Записываем заголовки столбцов\n",
        "    for i in range(len(answers)):\n",
        "        writer.writerow([images_names[i], answers[i]])  # Записываем данные\n",
        "\n",
        "print(\"CSV файл успешно создан.\")\n"
      ],
      "metadata": {
        "id": "iB4llTwiWiTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Указываете путь к файлу CSV\n",
        "csv_path = \"convnet_output.csv\"\n",
        "\n",
        "# Чтение CSV файла и загрузка данных в DataFrame\n",
        "data = pd.read_csv(csv_path)\n",
        "\n",
        "# Выполнение операции вычитания 1 из столбца \"label\"\n",
        "data[\"label\"] = 1 - data[\"label\"]\n",
        "\n",
        "# Сохранение измененных данных обратно в CSV файл\n",
        "data.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"Столбец 'label' успешно изменен в файле convnet_output.csv.\")\n"
      ],
      "metadata": {
        "id": "4ilnvN0fOjYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сортировка csv файла. сначала будут идти изображения с раком, а потом без"
      ],
      "metadata": {
        "id": "y0iHxQhcXLuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import pandas as pd\n",
        "\n",
        "# Проверка, что количество элементов в обоих массивах одинаково\n",
        "if len(answers) != len(images_names):\n",
        "    print(\"Количество элементов в массивах не совпадает.\")\n",
        "    exit()\n",
        "\n",
        "# Создание DataFrame из данных массивов\n",
        "data = pd.DataFrame({\"id\": images_names, \"label\": answers})\n",
        "\n",
        "# Сортировка DataFrame по столбцу 'label' в порядке убывания\n",
        "sorted_data = data.sort_values(\"label\", ascending=False)\n",
        "\n",
        "# Запись отсортированных данных в CSV файл\n",
        "sorted_data.to_csv(\"output.csv\", index=False)\n",
        "\n",
        "print(\"CSV файл успешно создан и строки отсортированы.\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y_zynrNXKWV",
        "outputId": "01b7b803-c804-4f8a-871d-a9133c587e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV файл успешно создан и строки отсортированы.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = \"output.csv\"\n",
        "\n",
        "data = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "fFLX45gIcq3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Dfuwn-d0ctRV",
        "outputId": "3837a511-134e-4aa4-f927-8d15eec9b714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             id     label\n",
              "0      00006537328c33e284c973d7b39d340809f7271b  0.000396\n",
              "1      0000ec92553fda4ce39889f9226ace43cae3364e  0.017440\n",
              "2      00024a6dee61f12f7856b0fc6be20bc7a48ba3d2  0.028344\n",
              "3      000253dfaa0be9d0d100283b22284ab2f6b643f6  0.997167\n",
              "4      000270442cc15af719583a8172c87cd2bd9c7746  0.999118\n",
              "...                                         ...       ...\n",
              "57453  fffdd1cbb1ac0800f65309f344dd15e9331e1c53  0.890489\n",
              "57454  fffdf4b82ba01f9cae88b9fa45be103344d9f6e3  0.990155\n",
              "57455  fffec7da56b54258038b0d382b3d55010eceb9d7  0.997106\n",
              "57456  ffff276d06a9e3fffc456f2a5a7a3fd1a2d322c6  0.851479\n",
              "57457  ffffeb4c0756098c7f589b7beec08ef1899093b5  0.894040\n",
              "\n",
              "[57458 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a068ae7-d859-4642-be8a-c3287bb82b71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00006537328c33e284c973d7b39d340809f7271b</td>\n",
              "      <td>0.000396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000ec92553fda4ce39889f9226ace43cae3364e</td>\n",
              "      <td>0.017440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00024a6dee61f12f7856b0fc6be20bc7a48ba3d2</td>\n",
              "      <td>0.028344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000253dfaa0be9d0d100283b22284ab2f6b643f6</td>\n",
              "      <td>0.997167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000270442cc15af719583a8172c87cd2bd9c7746</td>\n",
              "      <td>0.999118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57453</th>\n",
              "      <td>fffdd1cbb1ac0800f65309f344dd15e9331e1c53</td>\n",
              "      <td>0.890489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57454</th>\n",
              "      <td>fffdf4b82ba01f9cae88b9fa45be103344d9f6e3</td>\n",
              "      <td>0.990155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57455</th>\n",
              "      <td>fffec7da56b54258038b0d382b3d55010eceb9d7</td>\n",
              "      <td>0.997106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57456</th>\n",
              "      <td>ffff276d06a9e3fffc456f2a5a7a3fd1a2d322c6</td>\n",
              "      <td>0.851479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57457</th>\n",
              "      <td>ffffeb4c0756098c7f589b7beec08ef1899093b5</td>\n",
              "      <td>0.894040</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57458 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a068ae7-d859-4642-be8a-c3287bb82b71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a068ae7-d859-4642-be8a-c3287bb82b71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a068ae7-d859-4642-be8a-c3287bb82b71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}